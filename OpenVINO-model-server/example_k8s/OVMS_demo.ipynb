{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Model Server demo in Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code needed to follow the demo is included in \n",
    "[https://github.com/IntelAI/OpenVINO-model-server](https://github.com/IntelAI/OpenVINO-model-server) repo.\n",
    "It assumes `kubectl` is configured and permissions are granted to create new deployment and service records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'OpenVINO-model-server'...\n",
      "remote: Enumerating objects: 178, done.\u001b[K\n",
      "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
      "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
      "remote: Total 882 (delta 107), reused 89 (delta 53), pack-reused 704\u001b[K\n",
      "Receiving objects: 100% (882/882), 2.61 MiB | 12.60 MiB/s, done.\n",
      "Resolving deltas: 100% (516/516), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IntelAI/OpenVINO-model-server.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is exemplary deployment and service record to be added in Kubernetes.\n",
    "It serves ResNet50 model quantizied to INT8 precision. It was converted to OpenVINO format based from Caffe framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "apiVersion: apps/v1\r\n",
      "kind: Deployment\r\n",
      "metadata:\r\n",
      "  name: ovms\r\n",
      "  labels:\r\n",
      "    app: ovms\r\n",
      "spec:\r\n",
      "  selector:\r\n",
      "    matchLabels:\r\n",
      "       app: ovms\r\n",
      "  replicas: 2\r\n",
      "  template:\r\n",
      "    metadata:\r\n",
      "      labels:\r\n",
      "        app: ovms\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - name: ovms-resnet\r\n",
      "        image: intelaipg/openvino-model-server:latest\r\n",
      "        ports:\r\n",
      "        - containerPort: 80\r\n",
      "        env:\r\n",
      "        - name: LOG_LEVEL\r\n",
      "          value: \"DEBUG\"\r\n",
      "        command: [\"/ie-serving-py/start_server.sh\"]\r\n",
      "        args: [\"ie_serving\", \"model\", \"--model_path\", \"gs://intelai_public_models/resnet_50_i8\", \"--model_name\", \"resnet\", \"--port\", \"80\", \"--batch_size\", \"auto\"]\r\n",
      "---\r\n",
      "apiVersion: v1\r\n",
      "kind: Service\r\n",
      "metadata:\r\n",
      "  name: ovms-resnet\r\n",
      "spec:\r\n",
      "  selector:\r\n",
      "    app: ovms\r\n",
      "  ports:\r\n",
      "  - protocol: TCP\r\n",
      "    port: 80\r\n",
      "    targetPort: 80\r\n"
     ]
    }
   ],
   "source": [
    "!cat OpenVINO-model-server/example_k8s/openvino_model_server_resnet.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/ovms unchanged\r\n",
      "service/ovms-resnet unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n kubeflow -f OpenVINO-model-server/example_k8s/openvino_model_server_resnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now 2 replicas of OpenVINO Model Server are deployed and service ovms-renset is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovms-resnet                              ClusterIP   10.47.249.38    <none>        80/TCP              1h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service -n kubeflow | grep ovms-resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\n",
      "ovms   2         2         2            2           1h\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment -n kubeflow ovms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the usage of OVMS service, it is used by a client application in python. \n",
    "Identical client can submit the inference requests to TensorFlow Serving.\n",
    "The client is submitting for classification JPEG images from the input file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/airliner.jpeg 404\r\n",
      "images/arctic-fox.jpeg 279\r\n",
      "images/bee.jpeg 309\r\n",
      "images/golden_retriever.jpeg 207\r\n",
      "images/gorilla.jpeg 366\r\n",
      "images/magnetic_compass.jpeg 635\r\n",
      "images/peacock.jpeg 84\r\n",
      "images/pelican.jpeg 144\r\n",
      "images/snail.jpeg 113\r\n",
      "images/zebra.jpeg 340"
     ]
    }
   ],
   "source": [
    "!cd OpenVINO-model-server/example_client && cat input_images.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airliner.jpeg ![example image](https://github.com/IntelAI/OpenVINO-model-server/raw/master/example_client/images/airliner.jpeg)\n",
    "arctic-fox.jpeg ![example image](https://github.com/IntelAI/OpenVINO-model-server/raw/master/example_client/images/arctic-fox.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client dependencies needs to be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r OpenVINO-model-server/example_client/client_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client `get_serving_meta.py` display information about the served model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Getting model metadata for model:', 'resnet')\n",
      "Inputs metadata:\n",
      "\tInput name: data; shape: [1L, 3L, 224L, 224L]; dtype: DT_FLOAT\n",
      "Outputs metadata:\n",
      "\tOutput name: prob; shape: [1L, 1000L]; dtype: DT_FLOAT\n"
     ]
    }
   ],
   "source": [
    "!cd OpenVINO-model-server/example_client/ \\\n",
    "&& python get_serving_meta.py --grpc_address ovms-resnet.kubeflow --grpc_port 80 --model_name resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client `jpeg_classification.py` run the inference requests with images listed in the input file.\n",
    "Classification results along with expected labels are included in the output.\n",
    "\n",
    "In the output summary there are listed model metrics calculated based on the execution:\n",
    "    - accuracy\n",
    "    - average latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing:\n",
      "\tModel name: resnet\n",
      "\tImages list file: input_images.txt\n",
      "('images/airliner.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 383.00 ms; speed 2.00 fps', 2.61)\n",
      "('Detected:', 404, ' Should be:', '404')\n",
      "('images/arctic-fox.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 511.00 ms; speed 2.00 fps', 1.96)\n",
      "('Detected:', 279, ' Should be:', '279')\n",
      "('images/bee.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 192.00 ms; speed 2.00 fps', 5.22)\n",
      "('Detected:', 309, ' Should be:', '309')\n",
      "('images/golden_retriever.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 197.00 ms; speed 2.00 fps', 5.07)\n",
      "('Detected:', 207, ' Should be:', '207')\n",
      "('images/gorilla.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 308.00 ms; speed 2.00 fps', 3.25)\n",
      "('Detected:', 366, ' Should be:', '366')\n",
      "('images/magnetic_compass.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 247.0)\n",
      "('Processing time: 441.00 ms; speed 2.00 fps', 2.27)\n",
      "('Detected:', 635, ' Should be:', '635')\n",
      "('images/peacock.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 118.00 ms; speed 2.00 fps', 8.47)\n",
      "('Detected:', 84, ' Should be:', '84')\n",
      "('images/pelican.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 142.00 ms; speed 2.00 fps', 7.03)\n",
      "('Detected:', 144, ' Should be:', '144')\n",
      "('images/snail.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 248.0)\n",
      "('Processing time: 246.00 ms; speed 2.00 fps', 4.06)\n",
      "('Detected:', 113, ' Should be:', '113')\n",
      "('images/zebra.jpeg', (1, 3, 224, 224), '; data range:', 0.0, ':', 255.0)\n",
      "('Processing time: 312.00 ms; speed 2.00 fps', 3.2)\n",
      "('Detected:', 340, ' Should be:', '340')\n",
      "('Overall accuracy=', 100, '%')\n",
      "('Average latency=', 284.9, 'ms')\n"
     ]
    }
   ],
   "source": [
    "!cd OpenVINO-model-server/example_client/ \\\n",
    "&& python jpeg_classification.py --images_list input_images.txt \\\n",
    "--grpc_address ovms-resnet.kubeflow --grpc_port 80 \\\n",
    "--input_name data --output_name prob --size 224 --model_name resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a reference, info about the CPU spec on the Jupyter host is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              2\r\n",
      "On-line CPU(s) list: 0,1\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  1\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               79\r\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\r\n",
      "Stepping:            0\r\n",
      "CPU MHz:             2200.000\r\n",
      "BogoMIPS:            4400.00\r\n",
      "Hypervisor vendor:   KVM\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            56320K\r\n",
      "NUMA node0 CPU(s):   0,1\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat arch_capabilities\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
